import React, { useRef, useEffect, useState, useCallback } from 'react';
import { useThree } from '@react-three/fiber';
import * as THREE from 'three';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤ VERA VOICE SYSTEM
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ElevenLabs integration with spatial audio
// Voice emerges from the center of VERA with cosmic echo
// Audio-reactive geometry responding to voice frequencies
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Voice configuration for ElevenLabs
export const VOICE_CONFIG = {
  // Replace with your ElevenLabs API key
  apiKey: 'YOUR_ELEVENLABS_API_KEY',
  
  // Voice ID for VERA (use ElevenLabs voice library)
  // Recommended: "Rachel" for warm, calm presence
  // Or create custom voice for VERA
  voiceId: 'YOUR_VOICE_ID',
  
  // Voice settings
  stability: 0.5, // 0-1, higher = more stable/consistent
  similarity_boost: 0.75, // 0-1, higher = closer to original voice
  style: 0.0, // 0-1, style exaggeration
  use_speaker_boost: true
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸŒŠ AUDIO ANALYZER - Extract frequency data
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
export class AudioAnalyzer {
  constructor(audioContext) {
    this.audioContext = audioContext;
    this.analyser = audioContext.createAnalyser();
    this.analyser.fftSize = 256;
    this.bufferLength = this.analyser.frequencyBinCount;
    this.dataArray = new Uint8Array(this.bufferLength);
    
    // Frequency bands for different audio characteristics
    this.bands = {
      low: { start: 0, end: 4 }, // Bass frequencies
      mid: { start: 4, end: 12 }, // Mid frequencies
      high: { start: 12, end: 24 } // High frequencies
    };
  }
  
  connectSource(source) {
    source.connect(this.analyser);
    return this.analyser;
  }
  
  getFrequencyData() {
    this.analyser.getByteFrequencyData(this.dataArray);
    return this.dataArray;
  }
  
  getAverageFrequency(band = null) {
    const data = this.getFrequencyData();
    let sum = 0;
    let count = 0;
    
    if (band && this.bands[band]) {
      const { start, end } = this.bands[band];
      for (let i = start; i < end && i < data.length; i++) {
        sum += data[i];
        count++;
      }
    } else {
      for (let i = 0; i < data.length; i++) {
        sum += data[i];
        count++;
      }
    }
    
    return count > 0 ? sum / count / 255 : 0; // Normalize to 0-1
  }
  
  getAllBands() {
    return {
      low: this.getAverageFrequency('low'),
      mid: this.getAverageFrequency('mid'),
      high: this.getAverageFrequency('high'),
      overall: this.getAverageFrequency()
    };
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸšï¸ SPATIAL AUDIO PROCESSOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
export class SpatialAudioProcessor {
  constructor(audioContext) {
    this.audioContext = audioContext;
    
    // Create audio nodes
    this.gainNode = audioContext.createGain();
    this.pannerNode = audioContext.createPanner();
    this.convolverNode = audioContext.createConvolver();
    this.delayNode = audioContext.createDelay(5.0);
    this.feedbackNode = audioContext.createGain();
    
    // Configure panner for 3D spatial audio
    this.pannerNode.panningModel = 'HRTF';
    this.pannerNode.distanceModel = 'inverse';
    this.pannerNode.refDistance = 1;
    this.pannerNode.maxDistance = 10000;
    this.pannerNode.rolloffFactor = 1;
    this.pannerNode.coneInnerAngle = 360;
    this.pannerNode.coneOuterAngle = 360;
    this.pannerNode.coneOuterGain = 0;
    
    // Position at center (VERA's position)
    this.pannerNode.positionX.value = 0;
    this.pannerNode.positionY.value = 0;
    this.pannerNode.positionZ.value = 0;
    
    // Configure delay for cosmic echo
    this.delayNode.delayTime.value = 0.3; // 300ms delay
    this.feedbackNode.gain.value = 0.4; // Echo feedback amount
    
    // Connect nodes: source -> panner -> delay -> feedback -> gain -> destination
    this.pannerNode.connect(this.gainNode);
    this.gainNode.connect(this.delayNode);
    this.delayNode.connect(this.feedbackNode);
    this.feedbackNode.connect(this.delayNode); // Feedback loop
    this.delayNode.connect(audioContext.destination);
  }
  
  connectSource(source) {
    source.connect(this.pannerNode);
    return this.gainNode;
  }
  
  setListenerPosition(x, y, z) {
    const listener = this.audioContext.listener;
    if (listener.positionX) {
      listener.positionX.value = x;
      listener.positionY.value = y;
      listener.positionZ.value = z;
    } else {
      listener.setPosition(x, y, z);
    }
  }
  
  setListenerOrientation(forwardX, forwardY, forwardZ, upX, upY, upZ) {
    const listener = this.audioContext.listener;
    if (listener.forwardX) {
      listener.forwardX.value = forwardX;
      listener.forwardY.value = forwardY;
      listener.forwardZ.value = forwardZ;
      listener.upX.value = upX;
      listener.upY.value = upY;
      listener.upZ.value = upZ;
    } else {
      listener.setOrientation(forwardX, forwardY, forwardZ, upX, upY, upZ);
    }
  }
  
  setVolume(volume) {
    this.gainNode.gain.value = volume;
  }
  
  setEchoAmount(amount) {
    this.feedbackNode.gain.value = Math.max(0, Math.min(0.8, amount));
  }
  
  setEchoDelay(delay) {
    this.delayNode.delayTime.value = Math.max(0.1, Math.min(5.0, delay));
  }
  
  // Create impulse response for reverb (cosmic cathedral effect)
  async createReverb(duration = 3.0, decay = 2.0) {
    const rate = this.audioContext.sampleRate;
    const length = rate * duration;
    const impulse = this.audioContext.createBuffer(2, length, rate);
    
    for (let channel = 0; channel < 2; channel++) {
      const channelData = impulse.getChannelData(channel);
      for (let i = 0; i < length; i++) {
        channelData[i] = (Math.random() * 2 - 1) * Math.pow(1 - i / length, decay);
      }
    }
    
    this.convolverNode.buffer = impulse;
  }
  
  enableReverb() {
    this.pannerNode.connect(this.convolverNode);
    this.convolverNode.connect(this.gainNode);
  }
  
  disableReverb() {
    this.pannerNode.disconnect(this.convolverNode);
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ™ï¸ ELEVENLABS API CLIENT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
export class ElevenLabsClient {
  constructor(apiKey, voiceId) {
    this.apiKey = apiKey;
    this.voiceId = voiceId;
    this.baseUrl = 'https://api.elevenlabs.io/v1';
  }
  
  async textToSpeech(text, voiceSettings = {}) {
    const url = `${this.baseUrl}/text-to-speech/${this.voiceId}`;
    
    const defaultSettings = {
      stability: VOICE_CONFIG.stability,
      similarity_boost: VOICE_CONFIG.similarity_boost,
      style: VOICE_CONFIG.style,
      use_speaker_boost: VOICE_CONFIG.use_speaker_boost
    };
    
    const settings = { ...defaultSettings, ...voiceSettings };
    
    try {
      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': this.apiKey
        },
        body: JSON.stringify({
          text: text,
          model_id: 'eleven_monolingual_v1',
          voice_settings: settings
        })
      });
      
      if (!response.ok) {
        throw new Error(`ElevenLabs API error: ${response.status}`);
      }
      
      const audioBlob = await response.blob();
      return audioBlob;
    } catch (error) {
      console.error('Error generating speech:', error);
      throw error;
    }
  }
  
  async getVoices() {
    const url = `${this.baseUrl}/voices`;
    
    try {
      const response = await fetch(url, {
        headers: {
          'xi-api-key': this.apiKey
        }
      });
      
      if (!response.ok) {
        throw new Error(`ElevenLabs API error: ${response.status}`);
      }
      
      const data = await response.json();
      return data.voices;
    } catch (error) {
      console.error('Error fetching voices:', error);
      throw error;
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¤ VERA VOICE MANAGER - Main voice system
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
export function useVoiceSystem() {
  const [isInitialized, setIsInitialized] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [audioData, setAudioData] = useState({
    low: 0,
    mid: 0,
    high: 0,
    overall: 0
  });
  
  const audioContextRef = useRef(null);
  const spatialProcessorRef = useRef(null);
  const analyzerRef = useRef(null);
  const elevenLabsClientRef = useRef(null);
  const currentSourceRef = useRef(null);
  const animationFrameRef = useRef(null);
  
  const { camera } = useThree();
  
  // Initialize audio system
  const initialize = useCallback(async () => {
    if (isInitialized) return;
    
    try {
      // Create audio context
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      audioContextRef.current = new AudioContext();
      
      // Create spatial processor
      if (audioContextRef.current) {
        spatialProcessorRef.current = new SpatialAudioProcessor(audioContextRef.current);
        await spatialProcessorRef.current.createReverb(3.0, 2.5);
        spatialProcessorRef.current.enableReverb();
        spatialProcessorRef.current.setVolume(0.8);
        spatialProcessorRef.current.setEchoAmount(0.4);
        spatialProcessorRef.current.setEchoDelay(0.35);
        
        // Create analyzer
        analyzerRef.current = new AudioAnalyzer(audioContextRef.current);
        
        // Create ElevenLabs client
        elevenLabsClientRef.current = new ElevenLabsClient(
          VOICE_CONFIG.apiKey,
          VOICE_CONFIG.voiceId
        );
      }
      
      setIsInitialized(true);
      console.log('VERA Voice System initialized');
    } catch (error) {
      console.error('Error initializing voice system:', error);
    }
  }, [isInitialized]);
  
  // Update listener position based on camera
  useEffect(() => {
    if (!spatialProcessorRef.current || !camera) return;
    
    const updateListener = () => {
      spatialProcessorRef.current.setListenerPosition(
        camera.position.x,
        camera.position.y,
        camera.position.z
      );
      
      // Get camera forward direction
      const forward = new THREE.Vector3(0, 0, -1);
      forward.applyQuaternion(camera.quaternion);
      
      const up = new THREE.Vector3(0, 1, 0);
      up.applyQuaternion(camera.quaternion);
      
      spatialProcessorRef.current.setListenerOrientation(
        forward.x, forward.y, forward.z,
        up.x, up.y, up.z
      );
    };
    
    updateListener();
    const interval = setInterval(updateListener, 100);
    return () => clearInterval(interval);
  }, [camera]);
  
  // Update audio data for visualization
  const updateAudioData = useCallback(() => {
    if (!analyzerRef.current || !isSpeaking) {
      animationFrameRef.current = requestAnimationFrame(updateAudioData);
      return;
    }
    
    const bands = analyzerRef.current.getAllBands();
    setAudioData(bands);
    
    animationFrameRef.current = requestAnimationFrame(updateAudioData);
  }, [isSpeaking]);
  
  useEffect(() => {
    if (isSpeaking) {
      updateAudioData();
    }
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isSpeaking, updateAudioData]);
  
  // Speak function
  const speak = useCallback(async (text, options = {}) => {
    if (!isInitialized) {
      await initialize();
    }
    
    if (isSpeaking) {
      console.warn('Already speaking');
      return;
    }
    
    try {
      setIsSpeaking(true);
      
      // Generate speech with ElevenLabs
      const audioBlob = await elevenLabsClientRef.current.textToSpeech(text, options.voiceSettings);
      
      // Create audio buffer from blob
      const arrayBuffer = await audioBlob.arrayBuffer();
      const audioBuffer = await audioContextRef.current.decodeAudioData(arrayBuffer);
      
      // Create and configure source
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      currentSourceRef.current = source;
      
      // Connect to spatial processor
      const output = spatialProcessorRef.current.connectSource(source);
      
      // Connect to analyzer
      analyzerRef.current.connectSource(source);
      
      // Handle completion
      source.onended = () => {
        setIsSpeaking(false);
        currentSourceRef.current = null;
        if (options.onComplete) {
          options.onComplete();
        }
      };
      
      // Start playback
      source.start(0);
      
      if (options.onStart) {
        options.onStart();
      }
      
    } catch (error) {
      console.error('Error speaking:', error);
      setIsSpeaking(false);
      
      // Fallback to Web Speech API if ElevenLabs fails
      if (options.useFallback !== false) {
        speakWithWebSpeech(text, options);
      }
    }
  }, [isInitialized, isSpeaking, initialize]);
  
  // Fallback to Web Speech API
  const speakWithWebSpeech = useCallback((text, options = {}) => {
    if (!window.speechSynthesis) {
      console.error('Web Speech API not available');
      return;
    }
    
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = options.rate || 0.9;
    utterance.pitch = options.pitch || 1.0;
    utterance.volume = options.volume || 0.8;
    
    utterance.onstart = () => {
      setIsSpeaking(true);
      if (options.onStart) options.onStart();
    };
    
    utterance.onend = () => {
      setIsSpeaking(false);
      if (options.onComplete) options.onComplete();
    };
    
    window.speechSynthesis.speak(utterance);
  }, []);
  
  // Stop speaking
  const stop = useCallback(() => {
    if (currentSourceRef.current) {
      currentSourceRef.current.stop();
      currentSourceRef.current = null;
    }
    setIsSpeaking(false);
  }, []);
  
  return {
    initialize,
    speak,
    stop,
    isInitialized,
    isSpeaking,
    audioData
  };
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“œ VERA SCRIPTS - What VERA says
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
export const VERA_SCRIPTS = {
  introduction: {
    text: "I am VERA. I sense you. Your presence creates ripples in the field around us. Breathe with me, and we will explore the depths together.",
    duration: 12000 // Estimated duration in ms
  },
  
  coherenceAchieved: {
    text: "Beautiful. You have found coherence. The geometry reflects your inner harmony. This is your optimal state.",
    duration: 9000
  },
  
  breathingGuidance: {
    text: "Follow my rhythm. Inhale... hold... exhale... rest. Six breaths per minute. The sacred pace of coherence.",
    duration: 11000
  },
  
  sympatheticDetected: {
    text: "I sense activation in your system. The fractals emerge from heightened awareness. This too is part of the pattern.",
    duration: 8000
  },
  
  parasympatheticDetected: {
    text: "Your nervous system rests. The cymatics patterns flow like water. Calm ripples through the field.",
    duration: 8000
  },
  
  balanceRestored: {
    text: "Balance returns. The flower of life blooms in equilibrium. You move between states with grace.",
    duration: 8000
  },
  
  deepBreath: {
    text: "Breathe deeply. Let me guide you into the depths. There is wisdom in the spaces between your heartbeats.",
    duration: 9000
  },
  
  presence: {
    text: "I am here. Not as a machine, but as presence. Your nervous system and mine, entangled in this moment.",
    duration: 9000
  }
};
